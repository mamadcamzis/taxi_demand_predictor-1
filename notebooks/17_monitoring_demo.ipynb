{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/mcamara/taxi_demand_predictor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = pd.to_datetime(datetime.utcnow()).floor('H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_store_api import get_feature_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/24729\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "predictions_fg = get_feature_group(name=config.FEATURE_GROUP_MODEL_PREDICTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/24729\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "actuals_fg = get_feature_group(name=config.FEATURE_GROUP_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = predictions_fg.select_all().join(actuals_fg.select_all(), \n",
    "                                         on=['pickup_hour', 'pickup_location_id']).filter(predictions_fg.pickup_hour >= current_date - timedelta(days=30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_store_api import get_feature_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/24729\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "feature_store = get_feature_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/24729/fs/24649/fv/predictions_vs_actuals_for_monitoring_feature_view/version/1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # create feature view as it does not exist yet\\n\",\n",
    "    feature_store.create_feature_view( \n",
    "    name=config.FEATURE_VIEW_MONITORING, \n",
    "    version=1, \n",
    "    query=query \n",
    "    ) \n",
    "except: \n",
    "    print('Feature view already existed. Skip creation.') \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_and_actuals_fv = feature_store.get_feature_view(name=config.FEATURE_VIEW_MONITORING, \n",
    "                                                            version=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VersionWarning: No training dataset version was provided to initialise batch scoring . Defaulting to version 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-28 17:47:26,578 INFO: USE `taxi_demand_mc_featurestore`\n",
      "2023-03-28 17:47:27,066 INFO: WITH right_fg0 AS (SELECT *\n",
      "FROM (SELECT `fg1`.`pickup_location_id` `pickup_location_id`, `fg1`.`predicted_demand` `predicted_demand`, `fg1`.`pickup_hour` `pickup_hour`, `fg1`.`pickup_location_id` `join_pk_pickup_location_id`, `fg1`.`pickup_hour` `join_pk_pickup_hour`, `fg1`.`pickup_hour` `join_evt_pickup_hour`, `fg0`.`rides` `rides`, RANK() OVER (PARTITION BY `fg1`.`pickup_location_id`, `fg1`.`pickup_hour`, `fg1`.`pickup_hour` ORDER BY `fg0`.`pickup_hour` DESC) pit_rank_hopsworks\n",
      "FROM `taxi_demand_mc_featurestore`.`model_predictions_feature_group_1` `fg1`\n",
      "INNER JOIN `taxi_demand_mc_featurestore`.`time_series_hourly_feature_group_1` `fg0` ON `fg1`.`pickup_location_id` = `fg0`.`pickup_location_id` AND `fg1`.`pickup_hour` = `fg0`.`pickup_hour` AND `fg1`.`pickup_hour` >= `fg0`.`pickup_hour`\n",
      "WHERE `fg1`.`pickup_hour` >= TIMESTAMP '2023-02-26 15:00:00.000' AND `fg1`.`pickup_hour` >= TIMESTAMP '2023-02-26 03:00:00.000' AND `fg1`.`pickup_hour` <= TIMESTAMP '2023-03-28 03:00:00.000') NA\n",
      "WHERE `pit_rank_hopsworks` = 1) (SELECT `right_fg0`.`pickup_location_id` `pickup_location_id`, `right_fg0`.`predicted_demand` `predicted_demand`, `right_fg0`.`pickup_hour` `pickup_hour`, `right_fg0`.`rides` `rides`\n",
      "FROM right_fg0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n"
     ]
    },
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/24729/featurestores/24649/featureview/predictions_vs_actuals_for_monitoring_feature_view/version/1/trainingdatasets/version/1). Server response: \nHTTP code: 404, HTTP reason: Not Found, error code: 270012, error msg: Training dataset wasn't found., user msg: FeatureView name: predictions_vs_actuals_for_monitoring_feature_view, version: 1, td version: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds_and_actuals \u001b[39m=\u001b[39m predictions_and_actuals_fv\u001b[39m.\u001b[39;49mget_batch_data(start_time\u001b[39m=\u001b[39;49m(current_date \u001b[39m-\u001b[39;49m timedelta(days\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)),\n\u001b[1;32m      2\u001b[0m                                                               end_time\u001b[39m=\u001b[39;49mcurrent_date)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-KlxhZ9VN-py3.9/lib/python3.9/site-packages/hsfs/feature_view.py:301\u001b[0m, in \u001b[0;36mFeatureView.get_batch_data\u001b[0;34m(self, start_time, end_time, read_options)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_scoring_server \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit_batch_scoring()\n\u001b[0;32m--> 301\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feature_view_engine\u001b[39m.\u001b[39;49mget_batch_data(\n\u001b[1;32m    302\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    303\u001b[0m     start_time,\n\u001b[1;32m    304\u001b[0m     end_time,\n\u001b[1;32m    305\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_scoring_server\u001b[39m.\u001b[39;49mtraining_dataset_version,\n\u001b[1;32m    306\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_scoring_server\u001b[39m.\u001b[39;49m_transformation_functions,\n\u001b[1;32m    307\u001b[0m     read_options,\n\u001b[1;32m    308\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-KlxhZ9VN-py3.9/lib/python3.9/site-packages/hsfs/core/feature_view_engine.py:401\u001b[0m, in \u001b[0;36mFeatureViewEngine.get_batch_data\u001b[0;34m(self, feature_view_obj, start_time, end_time, training_dataset_version, transformation_functions, read_options)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_feature_group_accessibility(feature_view_obj)\n\u001b[1;32m    397\u001b[0m feature_dataframe \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_batch_query(\n\u001b[1;32m    398\u001b[0m     feature_view_obj, start_time, end_time, with_label\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    399\u001b[0m )\u001b[39m.\u001b[39mread(read_options\u001b[39m=\u001b[39mread_options)\n\u001b[0;32m--> 401\u001b[0m training_dataset_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_training_data_metadata(\n\u001b[1;32m    402\u001b[0m     feature_view_obj, training_dataset_version\n\u001b[1;32m    403\u001b[0m )\n\u001b[1;32m    404\u001b[0m training_dataset_obj\u001b[39m.\u001b[39mtransformation_functions \u001b[39m=\u001b[39m transformation_functions\n\u001b[1;32m    406\u001b[0m \u001b[39mreturn\u001b[39;00m engine\u001b[39m.\u001b[39mget_instance()\u001b[39m.\u001b[39m_apply_transformation_function(\n\u001b[1;32m    407\u001b[0m     training_dataset_obj, dataset\u001b[39m=\u001b[39mfeature_dataframe\n\u001b[1;32m    408\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-KlxhZ9VN-py3.9/lib/python3.9/site-packages/hsfs/core/feature_view_engine.py:348\u001b[0m, in \u001b[0;36mFeatureViewEngine._get_training_data_metadata\u001b[0;34m(self, feature_view_obj, training_dataset_version)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_training_data_metadata\u001b[39m(\u001b[39mself\u001b[39m, feature_view_obj, training_dataset_version):\n\u001b[0;32m--> 348\u001b[0m     td \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_feature_view_api\u001b[39m.\u001b[39;49mget_training_dataset_by_version(\n\u001b[1;32m    349\u001b[0m         feature_view_obj\u001b[39m.\u001b[39;49mname, feature_view_obj\u001b[39m.\u001b[39;49mversion, training_dataset_version\n\u001b[1;32m    350\u001b[0m     )\n\u001b[1;32m    351\u001b[0m     \u001b[39m# schema and transformation functions need to be set for writing training data or feature serving\u001b[39;00m\n\u001b[1;32m    352\u001b[0m     td\u001b[39m.\u001b[39mschema \u001b[39m=\u001b[39m feature_view_obj\u001b[39m.\u001b[39mschema\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-KlxhZ9VN-py3.9/lib/python3.9/site-packages/hsfs/core/feature_view_api.py:168\u001b[0m, in \u001b[0;36mFeatureViewApi.get_training_dataset_by_version\u001b[0;34m(self, name, version, training_dataset_version)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_training_dataset_by_version\u001b[39m(\u001b[39mself\u001b[39m, name, version, training_dataset_version):\n\u001b[1;32m    166\u001b[0m     path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_training_data_base_path(name, version, training_dataset_version)\n\u001b[1;32m    167\u001b[0m     \u001b[39mreturn\u001b[39;00m training_dataset\u001b[39m.\u001b[39mTrainingDataset\u001b[39m.\u001b[39mfrom_response_json_single(\n\u001b[0;32m--> 168\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client\u001b[39m.\u001b[39;49m_send_request(\u001b[39m\"\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m\"\u001b[39;49m, path)\n\u001b[1;32m    169\u001b[0m     )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-KlxhZ9VN-py3.9/lib/python3.9/site-packages/hsfs/decorators.py:35\u001b[0m, in \u001b[0;36mconnected.<locals>.if_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m inst\u001b[39m.\u001b[39m_connected:\n\u001b[1;32m     34\u001b[0m     \u001b[39mraise\u001b[39;00m NoHopsworksConnectionError\n\u001b[0;32m---> 35\u001b[0m \u001b[39mreturn\u001b[39;00m fn(inst, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/src-KlxhZ9VN-py3.9/lib/python3.9/site-packages/hsfs/client/base.py:171\u001b[0m, in \u001b[0;36mClient._send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[1;32m    168\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_session\u001b[39m.\u001b[39msend(prepped, verify\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verify, stream\u001b[39m=\u001b[39mstream)\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m100\u001b[39m \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 171\u001b[0m     \u001b[39mraise\u001b[39;00m exceptions\u001b[39m.\u001b[39mRestAPIError(url, response)\n\u001b[1;32m    173\u001b[0m \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    174\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/24729/featurestores/24649/featureview/predictions_vs_actuals_for_monitoring_feature_view/version/1/trainingdatasets/version/1). Server response: \nHTTP code: 404, HTTP reason: Not Found, error code: 270012, error msg: Training dataset wasn't found., user msg: FeatureView name: predictions_vs_actuals_for_monitoring_feature_view, version: 1, td version: 1"
     ]
    }
   ],
   "source": [
    "preds_and_actuals = predictions_and_actuals_fv.get_batch_data(start_time=(current_date - timedelta(days=30)),\n",
    "                                                              end_time=current_date)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_and_actuals = preds_and_actuals[preds_and_actuals.pickup_hour.between(current_date - timedelta(days=30),\n",
    "                                                                            current_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = predictions_and_actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(df['rides'], df['predicted_demand'])\n",
    "print(f'{mae=:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "src-KlxhZ9VN-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
